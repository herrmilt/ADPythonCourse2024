{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acc60f85",
   "metadata": {},
   "source": [
    "# Digits recognition problem. Non CNN solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1fd22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    print('GPU', tf.test.gpu_device_name(), 'configured')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4868babf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the MNIST dataset (handwritten digit images with labels)\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd421e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(25):  # Display 25 images\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(training_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(training_labels[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274ad9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = training_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Reshape the data to include a channel dimension\n",
    "training_images = training_images.reshape(training_images.shape[0], 28, 28, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c481c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28, 1)),  # 1 = grayscale\n",
    "    Dense(units=50, activation='relu'),\n",
    "    Dense(units=50, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c32c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d874e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "num_training_images = training_images.shape[0]\n",
    "\n",
    "history = model.fit(\n",
    "    training_images, training_labels,\n",
    "    epochs=10,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(training_images, training_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05804a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('digit_non_CNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502627f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_non_cnn = load_model('digit_non_CNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec65fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_model_non_cnn(image):\n",
    "    resized_image = image.resize((28, 28))\n",
    "    # Convert the image to grayscale\n",
    "    grayscale_image = resized_image.convert(\"L\")\n",
    "    # Convert the image to a NumPy array\n",
    "    image_array = np.array(grayscale_image)\n",
    "\n",
    "    normalized_image = 1 - image_array / 255.0\n",
    "    reshaped_image = np.reshape(normalized_image, (1, 28, 28))\n",
    "    reshaped_image = reshaped_image.astype(np.float32)\n",
    "\n",
    "    predictions = model_non_cnn.predict(reshaped_image)\n",
    "    print(np.trunc(predictions * 100))\n",
    "\n",
    "    # Get the predicted class index\n",
    "    predicted_class = np.argmax(predictions)\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e974a94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageTk, Image, ImageDraw\n",
    "import PIL\n",
    "from tkinter import *\n",
    "\n",
    "def paint_and_model():\n",
    "\n",
    "    width = 200  # canvas width\n",
    "    height = 200 # canvas height\n",
    "    center = height//2\n",
    "    white = (255, 255, 255) # canvas back\n",
    "\n",
    "    def paint(event):\n",
    "        x1, y1 = (event.x - 1), (event.y - 1)\n",
    "        x2, y2 = (event.x + 1), (event.y + 1)\n",
    "        canvas.create_oval(x1, y1, x2, y2, fill=\"black\",width=15)\n",
    "        draw.line([x1, y1, x2, y2],fill=\"black\",width=15)\n",
    "\n",
    "    master = Tk()\n",
    "\n",
    "    def close_window():\n",
    "        master.destroy()\n",
    "        \n",
    "    def clear_window():\n",
    "        canvas.delete(\"all\")\n",
    "        output_image.paste((255, 255, 255), (0, 0, width, height))        \n",
    "    \n",
    "    def do_classify():\n",
    "        non_cnn_class = classify_model_non_cnn(output_image)\n",
    "        classification_label.config(text=f\"NonCNN:{non_cnn_class}\")\n",
    "\n",
    "\n",
    "    # create a tkinter canvas to draw on\n",
    "    canvas = Canvas(master, width=width, height=height, bg='white')\n",
    "    canvas.pack()\n",
    "\n",
    "    # create an empty PIL image and draw object to draw on\n",
    "    output_image = PIL.Image.new(\"RGB\", (width, height), white)\n",
    "    draw = ImageDraw.Draw(output_image)\n",
    "    canvas.pack(expand=YES, fill=BOTH)\n",
    "    canvas.bind(\"<B1-Motion>\", paint)\n",
    "    \n",
    "    classification_label = Label(master, text=\"\", font=(\"Courier Bold\", 15))\n",
    "    classification_label.pack()\n",
    "\n",
    "    b1=Button(text=\"classify\",command=do_classify)\n",
    "    b1.pack(side=LEFT)\n",
    "    \n",
    "    button=Button(text=\"clear\",command=clear_window)\n",
    "    button.pack(side=LEFT)\n",
    "        \n",
    "    button=Button(text=\"close\",command=close_window)\n",
    "    button.pack(side=LEFT)\n",
    "    \n",
    "    master.mainloop()\n",
    "    \n",
    "paint_and_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0c45d5",
   "metadata": {},
   "source": [
    "## Recognizing digits with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede56abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the model\n",
    "model = models.Sequential([\n",
    "    # First convolutional layer\n",
    "    layers.Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Second convolutional layer\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Third convolutional layer\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    \n",
    "    # Fourth convolutional layer\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    \n",
    "    # Flattening the 3D output to 1D before feeding it into the dense layer\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    # Dense layers for classification\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')  # For 10 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Model summary to see the architecture and parameters\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9918d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d3ba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "num_training_images = training_images.shape[0]\n",
    "\n",
    "history = model.fit(\n",
    "    training_images, training_labels,\n",
    "    epochs=10,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(training_images, training_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef8ef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('digit_CNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff741f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = load_model('digit_CNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed19f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_model_cnn(image):\n",
    "    resized_image = image.resize((28, 28))\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    grayscale_image = resized_image.convert(\"L\")\n",
    "\n",
    "    # Convert the image to a NumPy array\n",
    "    image_array = np.array(grayscale_image)\n",
    "\n",
    "    normalized_image = image_array / 255.0\n",
    "    reshaped_image = np.reshape(normalized_image, (1, 28, 28, 1))\n",
    "#     reshaped_image = reshaped_image.astype(np.float32)\n",
    "    predictions = model_cnn.predict(1 - reshaped_image)\n",
    "\n",
    "    # Get the predicted class index\n",
    "    predicted_class_index = np.argmax(predictions)\n",
    "    predict_label = classes[predicted_class_index]\n",
    "    return predict_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca8c3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageTk, Image, ImageDraw\n",
    "import PIL\n",
    "from tkinter import *\n",
    "\n",
    "def paint_and_model():\n",
    "\n",
    "    width = 200  # canvas width\n",
    "    height = 200 # canvas height\n",
    "    center = height//2\n",
    "    white = (255, 255, 255) # canvas back\n",
    "\n",
    "    def paint(event):\n",
    "        x1, y1 = (event.x - 1), (event.y - 1)\n",
    "        x2, y2 = (event.x + 1), (event.y + 1)\n",
    "        canvas.create_oval(x1, y1, x2, y2, fill=\"black\",width=15)\n",
    "        draw.line([x1, y1, x2, y2],fill=\"black\",width=15)\n",
    "\n",
    "    master = Tk()\n",
    "\n",
    "    def close_window():\n",
    "        master.destroy()\n",
    "        \n",
    "    def clear_window():\n",
    "        canvas.delete(\"all\")\n",
    "        output_image.paste((255, 255, 255), (0, 0, width, height))        \n",
    "    \n",
    "    def do_classify():\n",
    "        cnn_class = classify_model_cnn(output_image)\n",
    "        non_cnn_class = classify_model_non_cnn(output_image)\n",
    "        classification_label.config(text=f\"NonCNN:{non_cnn_class}, CNN:{cnn_class}\")\n",
    "\n",
    "\n",
    "    # create a tkinter canvas to draw on\n",
    "    canvas = Canvas(master, width=width, height=height, bg='white')\n",
    "    canvas.pack()\n",
    "\n",
    "    # create an empty PIL image and draw object to draw on\n",
    "    output_image = PIL.Image.new(\"RGB\", (width, height), white)\n",
    "    draw = ImageDraw.Draw(output_image)\n",
    "    canvas.pack(expand=YES, fill=BOTH)\n",
    "    canvas.bind(\"<B1-Motion>\", paint)\n",
    "    \n",
    "    classification_label = Label(master, text=\"\", font=(\"Courier Bold\", 15))\n",
    "    classification_label.pack()\n",
    "\n",
    "    b1=Button(text=\"classify\",command=do_classify)\n",
    "    b1.pack(side=LEFT)\n",
    "    \n",
    "    button=Button(text=\"clear\",command=clear_window)\n",
    "    button.pack(side=LEFT)\n",
    "        \n",
    "    button=Button(text=\"close\",command=close_window)\n",
    "    button.pack(side=LEFT)\n",
    "    \n",
    "    master.mainloop()\n",
    "    \n",
    "paint_and_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf91469",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python_lectures]",
   "language": "python",
   "name": "conda-env-python_lectures-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
